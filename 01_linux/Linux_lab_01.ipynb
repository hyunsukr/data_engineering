{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3293849",
   "metadata": {},
   "source": [
    "# Linux lab 1: \n",
    "## In this lab you'll create a small classifier pipeline driven by the command line.\n",
    "\n",
    "### A sample trained naive bayes classifier will be provided as well as sample data.   Your tasks will be the following.\n",
    "* Use the command line to expand all the sample data that will be used in this exercise\n",
    "* Following the instructions provided, you will write a script named `classifier.py` that will\n",
    "    - Load the pretrained naive bayes classfier\n",
    "    - read stdin, it will expect that each line passed into it will be a path to a file to score for classification\n",
    "    - output the `score, filename` as output to stdout\n",
    "* You will then extend the command line pipeline to sort the scores-names so that the top ten scores are displayed at the command line\n",
    "\n",
    "As an example, if you had a bunch of files for which you needed the line count in a directory called `source`.  You could use the linux utility `wc` to get the line count of each by doing `ls easy_ham/* | xargs wc -l | sort -r | head -n 10`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2988e0",
   "metadata": {},
   "source": [
    "## Part 1.1 Expanding the sample files\n",
    "\n",
    "In this repository, under the directory called `data` you will see three files.\n",
    "* 20021010_easy_ham.tar.bz2\n",
    "* 20021010_hard_ham.tar.bz2\n",
    "* 20021010_spam.tar.bz2\n",
    "\n",
    "Use the `tar` utility to expand them.  Type `man tar` to bring up the linux documentation.  \n",
    "\n",
    "When expanded, you will see three directories now, giving. you a structure like this:\n",
    "```\n",
    ".\n",
    "├── 20021010_easy_ham.tar.bz2\n",
    "├── 20021010_hard_ham.tar.bz2\n",
    "├── 20021010_spam.tar.bz2\n",
    "├── easy_ham\n",
    "├── hard_ham\n",
    "└── spam\n",
    "```\n",
    "Where easy_ham, hard_ham and spam contain the expanded files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b4cd6b-de76-4a37-ab5c-50c9e8e858ec",
   "metadata": {},
   "source": [
    "![](pics_for_lab/tar_easy_ham.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334eb42-358f-4378-aedd-759ff34d2d6a",
   "metadata": {},
   "source": [
    "![](pics_for_lab/tar_hard_ham.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e7bb3-c467-4c95-8129-e3a7473c3e36",
   "metadata": {},
   "source": [
    "![](pics_for_lab/tar_spam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95599610-50a4-4485-941c-943a166a64c9",
   "metadata": {},
   "source": [
    "![](pics_for_lab/data_foler_after_tar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509a9c7",
   "metadata": {},
   "source": [
    "## Part 1.2 Creating a file to load the model and read stdin\n",
    "\n",
    "The classifier is in the naive_bayes.py file, and there is a stored file with the pretrained values.   Loading the file looks like\n",
    "\n",
    "```\n",
    "import naive_bayes as nb\n",
    "\n",
    "model = nb.NaiveBayesClassifier(k=0.5)\n",
    "model.load_from_file()\n",
    "```\n",
    "\n",
    "The call to load_from_file() will automatically load the pretrained settings.\n",
    "\n",
    "The next step is to use pythons, `sys` module, to read from stdin.  That way, when you `cat` output at it, it will be recieved in your script.\n",
    "\n",
    "What your script should expect, is to be sent file locations, from there you can iterate over the files \n",
    "\n",
    "A full template for this exercise is here:\n",
    "```\n",
    "import naive_bayes as nb\n",
    "import sys\n",
    "\n",
    "model = nb.NaiveBayesClassifier(k=0.5)\n",
    "model.load_from_file()\n",
    "\n",
    "\n",
    "def process_stdin(stream):\n",
    "    < PUT YOUR CODE HERE>\n",
    "\n",
    "def score_one_file(fname, model):\n",
    "    try:\n",
    "        sys.stderr.write(fname)\n",
    "        subject = \"\"\n",
    "        with open(fname, errors='ignore') as source:\n",
    "            for line in source:\n",
    "                if line.startswith(\"Subject:\"):\n",
    "                    subject = line.lstrip(\"Subject: \")\n",
    "\n",
    "        score = model.predict(subject)\n",
    "        formatted_return = \"{}\\t{}\".format(str(score), fname)\n",
    "        print(formatted_return)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(\"{}\\tUncaught Exception:\\t{}\".format(fname, e))\n",
    "\n",
    "\n",
    "files_to_score = process_stdin(sys.stdin)\n",
    "\n",
    "for fname in files_to_score:\n",
    "    score_one_file(fname, model)\n",
    "```\n",
    "\n",
    "Note that you're basically recieving stdin, iteraing over it and then passing the filtered content (only the subject line) to the classifier to score.\n",
    "\n",
    "At the end of this section you should be able to `echo <path to file> | python classifier` and see something like `0.432    <path to file>` printed on the console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752ee20-7453-40fb-ad94-a5e223803561",
   "metadata": {},
   "source": [
    "![](pics_for_lab/1.2_cli_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c8705",
   "metadata": {},
   "source": [
    "## Part 1.3 Building the command line mini pipeline\n",
    "\n",
    "Now that your classifier.py file reads from stdin and outputs a score to stdout, we can leverage the linux pipeline to classify a batch of files.\n",
    "\n",
    "We'll use the files you expanded in part 1.1.  The trick here is to issue an `ls` command that will list the files recursively down into the data directory for the files we want to score. More concretely we want to chain 4 commands together.\n",
    "\n",
    "* An `ls` command that lists our target files by path recursively into the data/directory\n",
    "* The call to the classifier receiving that list of files\n",
    "* The output of scores passed to the `sort` utility to order then by score, with the largest at the top\n",
    "* The output from sort passed to `head` to trim only the top 10 lines since we're looking for the top scored files.\n",
    "\n",
    "So the solution will take the shape of \n",
    "```\n",
    "ls <wildcards here> | python classifier.py | sort <flags to sort> | head <flags to head>\n",
    "```\n",
    "Which should out put something like\n",
    "```\n",
    "9.981655083641292e-05\tdata/easy_ham/0520.db2ae930623e1db4c9cf60676f96c4e5\n",
    "9.981655083641292e-05\tdata/easy_ham/0518.def6dfc3c2204dda12270b0ca97f0fc5\n",
    "9.981655083641292e-05\tdata/easy_ham/0512.17bff8553d7e8f6c668166afe149795b\n",
    "9.981655083641292e-05\tdata/easy_ham/0376.c0225fd19682f7ac58d090b6528af380\n",
    "9.981655083641292e-05\tdata/easy_ham/0375.54d0a570b81851127b73cebb8741a2df\n",
    "9.970924543171243e-05\tdata/hard_ham/0063.d84fa51cf5329f5e5b2f0c83b7ec94d0\n",
    "9.779274072567135e-09\tdata/easy_ham/0606.246043a69d2c710dde0e67eedb1fd853\n",
    "9.66684964867624e-06\tdata/easy_ham/0734.7dc0b0b5f6fb1977f0a146a44c4750aa\n",
    "9.66684964867624e-06\tdata/easy_ham/0731.59e8a707586a8b3cfe89bff4024dead7\n",
    "9.66684964867624e-06\tdata/easy_ham/0711.27203d4f43e71f7e1ced0cdd7f8685c8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c38b8-236d-4248-b1d1-adc0dcf92f82",
   "metadata": {},
   "source": [
    "Solution Command line output\n",
    "\n",
    "![](pics_for_lab/1.3_solution_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500d94a-f265-4a10-9855-62d0bd2e4e5b",
   "metadata": {},
   "source": [
    "CLI for only doing spam.\n",
    "![](pics_for_lab/1.3_spam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291a9b2",
   "metadata": {},
   "source": [
    "## Solution command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5d00bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.981655083641292e-05\tdata/easy_ham/0520.db2ae930623e1db4c9cf60676f96c4e5\n",
      "9.981655083641292e-05\tdata/easy_ham/0518.def6dfc3c2204dda12270b0ca97f0fc5\n",
      "9.981655083641292e-05\tdata/easy_ham/0512.17bff8553d7e8f6c668166afe149795b\n",
      "9.981655083641292e-05\tdata/easy_ham/0376.c0225fd19682f7ac58d090b6528af380\n",
      "9.981655083641292e-05\tdata/easy_ham/0375.54d0a570b81851127b73cebb8741a2df\n",
      "9.970924543171243e-05\tdata/hard_ham/0063.d84fa51cf5329f5e5b2f0c83b7ec94d0\n",
      "9.779274072567135e-09\tdata/easy_ham/0606.246043a69d2c710dde0e67eedb1fd853\n",
      "9.66684964867624e-06\tdata/easy_ham/0734.7dc0b0b5f6fb1977f0a146a44c4750aa\n",
      "9.66684964867624e-06\tdata/easy_ham/0731.59e8a707586a8b3cfe89bff4024dead7\n",
      "9.66684964867624e-06\tdata/easy_ham/0711.27203d4f43e71f7e1ced0cdd7f8685c8\n",
      "sort: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "! ls data/*/0* | python classifier.py 2> /dev/null | sort -rn | head -n 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
